{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Create Weighted Mol Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84hk5k16N1TR",
        "outputId": "9cf8dd73-ba7b-4a03-e11c-623a99d4a2b9"
      },
      "source": [
        "!git clone https://github.com/parkerburchett/pysmiles\n",
        "!pip install pyTDC\n",
        "!git clone https://github.com/parkerburchett/TDC-DeepLearning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pysmiles'...\n",
            "remote: Enumerating objects: 420, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 420 (delta 12), reused 18 (delta 4), pack-reused 390\u001b[K\n",
            "Receiving objects: 100% (420/420), 134.29 KiB | 5.17 MiB/s, done.\n",
            "Resolving deltas: 100% (251/251), done.\n",
            "Collecting pyTDC\n",
            "  Downloading PyTDC-0.3.2.tar.gz (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyTDC) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyTDC) (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyTDC) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyTDC) (0.22.2.post1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pyTDC) (0.11.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pyTDC) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyTDC) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pyTDC) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyTDC) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyTDC) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn->pyTDC) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->pyTDC) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->pyTDC) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->pyTDC) (1.3.2)\n",
            "Building wheels for collected packages: pyTDC\n",
            "  Building wheel for pyTDC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTDC: filename=PyTDC-0.3.2-py3-none-any.whl size=117596 sha256=d627a2f159363f2d2fb93b3821f84b09428b5f7415f1faf456ac6f496b47da0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/ef/02/99f35109c3a026965faad8b3cf0f8aeb3a9e01e069f40f8698\n",
            "Successfully built pyTDC\n",
            "Installing collected packages: fuzzywuzzy, pyTDC\n",
            "Successfully installed fuzzywuzzy-0.18.0 pyTDC-0.3.2\n",
            "Cloning into 'TDC-DeepLearning'...\n",
            "remote: Enumerating objects: 268, done.\u001b[K\n",
            "remote: Counting objects: 100% (268/268), done.\u001b[K\n",
            "remote: Compressing objects: 100% (209/209), done.\u001b[K\n",
            "remote: Total 268 (delta 97), reused 224 (delta 54), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (268/268), 49.21 MiB | 17.72 MiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n",
            "Checking out files: 100% (99/99), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgvnVkY8NQnF",
        "outputId": "06904518-2687-443d-f438-c7456efd2d1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import lightgbm as lgb\n",
        "import json\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from pysmiles.pysmiles import read_smiles\n",
        "import os\n",
        "os.chdir('/content/TDC-DeepLearning/')\n",
        "from utils import ColorRefinement as cr \n",
        "from tdc.benchmark_group import admet_group"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bobRpz_cNnmA",
        "outputId": "978b846a-b4ea-45c9-acc8-e0d30ca3bd15"
      },
      "source": [
        "best_models = json.load(open('/content/drive/MyDrive/SpringBoard/Therapeutic Data Commons Projects/HyperParamTuning/bestmodels.json', 'r'))\n",
        "best_models"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': \"{'colsample_bytree': 0.45921506474872353, 'learning_rate': 0.003605978989205916, 'n_estimators': 997, 'num_leaves': 171, 'reg_alpha': 0.06136193030050688, 'subsample': 0.664374000848817}\",\n",
              " '1': \"{'colsample_bytree': 0.19190373976042552, 'learning_rate': 0.018880733945270692, 'n_estimators': 772, 'num_leaves': 412, 'reg_alpha': 0.1319602189105627, 'subsample': 0.953435263598222}\",\n",
              " '2': \"{'colsample_bytree': 0.0846115062976256, 'learning_rate': 0.061904626017968235, 'n_estimators': 710, 'num_leaves': 218, 'reg_alpha': 0.09722107305351997, 'subsample': 0.7625401046034898}\",\n",
              " '3': \"{'colsample_bytree': 0.10234165146414909, 'learning_rate': 0.021876318417714605, 'n_estimators': 574, 'num_leaves': 193, 'reg_alpha': 0.08093256266597965, 'subsample': 0.9986613307559011}\",\n",
              " '4': \"{'colsample_bytree': 0.29036206035748535, 'learning_rate': 0.09316958191707549, 'n_estimators': 473, 'num_leaves': 101, 'reg_alpha': 0.1992406954388929, 'subsample': 0.005705227464680718}\"}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPT34ZXCNzB2"
      },
      "source": [
        "# load data\n",
        "import glob\n",
        "import lightgbm as lgb\n",
        "def get_larger_file_names():\n",
        "  \"\"\"\n",
        "    Returns the file locations for the 10_000 bucket color embeddings.\n",
        "  \"\"\"\n",
        "  return glob.glob('/content/drive/MyDrive/SpringBoard/Therapeutic Data Commons Projects/data/more_buckets_data/*hop_larger_embedding.csv')\n",
        "\n",
        "def load_feature_df(hop_num:int):\n",
        "  \"\"\"\n",
        "      Load all the color features, target of hop number hop nu\n",
        "      Return a dataframe of (color0, color1 ... color998,color999, target) of the insample training data\n",
        "  \"\"\"\n",
        "  hop_file_name = get_larger_file_names()[hop_num]\n",
        "  df = pd.read_csv(hop_file_name, index_col=0)\n",
        "  df = df.astype(np.int16)\n",
        "  group = admet_group(path = 'data/')\n",
        "  benchmark = group.get('cyp2c9_veith')\n",
        "  targets =  benchmark['train_val']['Y'].astype(np.bool)\n",
        "  df['target'] =  targets\n",
        "  return df\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "def compute_auprc(y_true, y_pred):\n",
        "    # https://stats.stackexchange.com/questions/157012/area-under-precision-recall-curve-auc-of-pr-curve-and-average-precision-ap\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
        "    area = round(auc(recall, precision), 6)\n",
        "    return area"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmUa9j5LOAsU",
        "outputId": "ad36b2ef-c80f-4691-c02a-a653c32dfbc9"
      },
      "source": [
        "def create_model_df_set(hop_num, params):\n",
        "  params_as_dict = json.loads(params.replace(\"'\", '\"'))\n",
        "  return {'hop_number' : hop_num,\n",
        "          'model_object': lgb.LGBMRegressor(**params_as_dict, subsample_freq=1),\n",
        "          'df' : load_feature_df(hop_num)}\n",
        "\n",
        "model_df_pairs = [create_model_df_set(i, best_models[str(i)]) for i in range(0,4)]\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n",
            "Found local copy...\n",
            "Found local copy...\n",
            "Found local copy...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "UL7opJVxm5_A",
        "outputId": "87511565-2e97-49fb-b612-ff5930c81dec"
      },
      "source": [
        "for d in model_df_pairs:\n",
        "\n",
        "  d['key'] = d.pop('hop_number')\n",
        "  d['training_df'] = d.pop('df')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-279007702577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_df_pairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hop_number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training_df'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'hop_number'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIfe91dqSkJ2"
      },
      "source": [
        "import pickle \n",
        "\n",
        "pickle.dump(model_df_pairs, open('/content/drive/MyDrive/SpringBoard/Therapeutic Data Commons Projects/HyperParamTuning/model_df_pairs.pkl', 'wb'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "Fuah4cBiS73q",
        "outputId": "063c681d-81cf-4be0-ede9-9709d5e098d6"
      },
      "source": [
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# df = model_df_pairs[0]['df']\n",
        "# features = [f for f in df.columns if 'color' in f]\n",
        "\n",
        "# kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
        "\n",
        "# X = df[features].values\n",
        "\n",
        "# prediction_dfs = []\n",
        "# # gets 25 predictions\n",
        "# for train_index, test_index in kf.split(X): # only used to get the indexes correct\n",
        "#   prediction_df = pd.DataFrame(index=test_index)\n",
        "\n",
        "#   for pairs in model_df_pairs:\n",
        "#     df = pairs['df']\n",
        "#     hop_num = pairs['hop_number']\n",
        "#     model = pairs['model_object']\n",
        "\n",
        "#     X = df[features].values\n",
        "#     y = df['target'].values\n",
        "\n",
        "#     X_train, X_test = X[train_index], X[test_index]\n",
        "#     y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "#     model.fit(X_train, y_train)\n",
        "#     prediction_df[f'model_{hop_num}'] = model.predict(X_test)\n",
        "\n",
        "#     if 'target' not in prediction_df.columns:\n",
        "#       prediction_df['target'] = y_test\n",
        "\n",
        "#   print(prediction_df.head())\n",
        "#   prediction_dfs.append(prediction_df)\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c8355a7bb308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_df_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'df'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'color'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'df'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q0M-L4-_sQx",
        "outputId": "140883b5-15ef-49f7-c079-7eac0337c1e7"
      },
      "source": [
        "model_df_pairs[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'key': 0,\n",
              " 'model_object': LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
              "               colsample_bytree=0.45921506474872353, importance_type='split',\n",
              "               learning_rate=0.003605978989205916, max_depth=-1,\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=997, n_jobs=-1, num_leaves=171, objective=None,\n",
              "               random_state=None, reg_alpha=0.06136193030050688, reg_lambda=0.0,\n",
              "               silent=True, subsample=0.664374000848817,\n",
              "               subsample_for_bin=200000, subsample_freq=1),\n",
              " 'training_df':        color_0  color_1  color_2  ...  color_9998  color_9999  target\n",
              " index                             ...                                \n",
              " 0            0        0        0  ...           0           0   False\n",
              " 1            0        0        0  ...           0           0   False\n",
              " 2            0        0        0  ...           0           0   False\n",
              " 3            0        0        0  ...           0           0   False\n",
              " 4            0        0        0  ...           0           0   False\n",
              " ...        ...      ...      ...  ...         ...         ...     ...\n",
              " 9668         0        0        0  ...           0           0    True\n",
              " 9669         0        0        0  ...           0           0    True\n",
              " 9670         0        0        0  ...           0           0    True\n",
              " 9671         0        0        0  ...           0           0   False\n",
              " 9672         0        0        0  ...           0           0    True\n",
              " \n",
              " [9673 rows x 10001 columns]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSxK2n6vhXUE",
        "outputId": "acf3898f-df54-4c5a-aedd-e90773234d53"
      },
      "source": [
        "\n",
        "df = model_df_pairs[0]['training_df']\n",
        "features = [f for f in df.columns if 'color' in f]\n",
        "\n",
        "def create_model_feature_pairs(model_objects:list, training_dfs:list) -> dict:\n",
        "  \"\"\"\n",
        "    Create a list of dictionaries of\n",
        "    {\n",
        "      key: an int id,\n",
        "      model_object: a model object\n",
        "      feature_df: a dataframe of features, and target to train model_object on\n",
        "    } \n",
        "\n",
        "    This is a component that is used to create a weighted classifier.\n",
        "    You can use this later on the full data to create the component for the prediction\n",
        "  \"\"\"\n",
        "  if len(model_objects) != len(training_dfs):\n",
        "    raise ValueError('you must pass in the same number of model and training dfs')\n",
        "  \n",
        "  model_feature_pairs = []\n",
        "  for key in range(len(model_objects)):\n",
        "    pair = {\n",
        "        'key':key,\n",
        "        'model_object': model_objects[key],\n",
        "        'training_df': training_dfs[key]\n",
        "    }\n",
        "    model_feature_pairs.append(pair)\n",
        "  \n",
        "  return model_feature_pairs\n",
        "\n",
        "def create_prediction_dfs_for_weighted_classifier(model_feature_pairs:list,\n",
        "                                                  k_fold_n_splits:int,\n",
        "                                                  k_fold_shuffle:bool,\n",
        "                                                  target_col:str) -> list:\n",
        "  \"\"\"\n",
        "\n",
        "    Create a list of dfs with shape\n",
        "    (len(model_feature_pairs) + 1, rows in a feature df /  k_fold_n_splits\n",
        "\n",
        "\n",
        "    [      \n",
        "            model_0  target   model_1   model_2   model_3\n",
        "    7739  0.255534   False  0.371322  0.581279  0.297537\n",
        "    7740 -0.022156   False -0.002481 -0.068137 -0.082516\n",
        "    7741  0.598179    True  0.423898  0.541822  0.675032\n",
        "    7742  0.208997   False  0.190605  0.110511  0.280596\n",
        "    7743  0.050421   False  0.128555  0.369134  0.347044\n",
        "    ,\n",
        "           model_0  target   model_1   model_2   model_3\n",
        "    1935  0.312784   False  0.208339  0.295249  0.286069\n",
        "    1936  0.334130    True  0.347660  0.449999  0.583438\n",
        "    1937  0.460933    True  0.445365  0.691044  0.297753\n",
        "    1938  0.426971    True  0.588611  0.686233  0.507866\n",
        "    1939  0.859865    True  0.984376  1.068336  0.679388\n",
        "    ]\n",
        "\n",
        "\n",
        "    You use this to create a weighted classifier later\n",
        "  \"\"\"\n",
        "\n",
        "  kf = KFold(n_splits=k_fold_n_splits, random_state=None, shuffle=k_fold_shuffle)\n",
        "\n",
        "  # this is ugly but is needed to do the Kfold splits\n",
        "  df = model_df_pairs[0]['training_df']\n",
        "  X = df[features].values\n",
        "  prediction_dfs = []\n",
        "\n",
        "  for train_index, test_index in kf.split(X): # only used to get the indexes correct\n",
        "    prediction_df = pd.DataFrame(index=test_index)\n",
        "\n",
        "    for pair in model_df_pairs:\n",
        "      \n",
        "      \n",
        "      key = pair['key']\n",
        "      training_df = pair['training_df']\n",
        "      model = pair['model_object']\n",
        "      feature_cols = [f for f in training_df.columns if f!=target_col]\n",
        "\n",
        "      X = training_df[feature_cols].values\n",
        "      y = training_df[target_col].values\n",
        "\n",
        "      X_train, X_test = X[train_index], X[test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "      model.fit(X_train, y_train)\n",
        "      prediction_df[f'model_{key}'] = model.predict(X_test)\n",
        "\n",
        "      if target_col not in prediction_df.columns:\n",
        "        prediction_df[target_col] = y_test\n",
        "\n",
        "    print(prediction_df.head())\n",
        "    prediction_dfs.append(prediction_df)\n",
        "    \n",
        "  return prediction_dfs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "prediction_dfs = create_prediction_dfs_for_weighted_classifier(\n",
        "                model_feature_pairs=model_df_pairs,\n",
        "                k_fold_n_splits=5,\n",
        "                k_fold_shuffle=False,\n",
        "                target_col='target'\n",
        "                )\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    model_0  target   model_1   model_2   model_3\n",
            "0  0.148717   False  0.168826  0.126168  0.326254\n",
            "1  0.147821   False  0.009772  0.011469  0.058126\n",
            "2  0.109165   False -0.164792  0.358199  0.199572\n",
            "3  0.147362   False  0.024964  0.317119  0.370499\n",
            "4  0.132685   False  0.315626  0.347921  0.351123\n",
            "       model_0  target   model_1   model_2   model_3\n",
            "1935  0.312784   False  0.208339  0.295249  0.286069\n",
            "1936  0.334130    True  0.347660  0.449999  0.583438\n",
            "1937  0.460933    True  0.445365  0.691044  0.297753\n",
            "1938  0.426971    True  0.588611  0.686233  0.507866\n",
            "1939  0.859865    True  0.984376  1.068336  0.679388\n",
            "       model_0  target   model_1   model_2   model_3\n",
            "3870  0.459636   False  0.447652  0.706204  0.545787\n",
            "3871  0.329500    True  0.449534  0.352346  0.194716\n",
            "3872  0.008223   False  0.123109 -0.060045  0.231775\n",
            "3873  0.577824   False  0.351500  0.414599  0.285807\n",
            "3874  0.687691    True  0.864578  0.972968  0.991008\n",
            "       model_0  target   model_1   model_2   model_3\n",
            "5805  0.261044   False  0.142227  0.157438  0.161204\n",
            "5806  0.533139    True  0.339514  0.497814  0.170840\n",
            "5807  0.392724   False  0.311528  0.424494  0.599304\n",
            "5808  0.183220   False  0.352198  0.642930  0.678630\n",
            "5809  0.387226   False  0.106226 -0.038921  0.063332\n",
            "       model_0  target   model_1   model_2   model_3\n",
            "7739  0.255534   False  0.371322  0.581279  0.297537\n",
            "7740 -0.022156   False -0.002481 -0.068137 -0.082516\n",
            "7741  0.598179    True  0.423898  0.541822  0.675032\n",
            "7742  0.208997   False  0.190605  0.110511  0.280596\n",
            "7743  0.050421   False  0.128555  0.369134  0.347044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "K8zj-W-GYS65",
        "outputId": "128dd582-d4bd-449b-d795-98622cf3a6ce"
      },
      "source": [
        "prediction_dfs[3] # example prediction on the test set at hop 3. Note this does not not look at the out of sample validation data.s\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_0</th>\n",
              "      <th>target</th>\n",
              "      <th>model_1</th>\n",
              "      <th>model_2</th>\n",
              "      <th>model_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5805</th>\n",
              "      <td>0.261044</td>\n",
              "      <td>False</td>\n",
              "      <td>0.142227</td>\n",
              "      <td>0.157438</td>\n",
              "      <td>0.161204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5806</th>\n",
              "      <td>0.533139</td>\n",
              "      <td>True</td>\n",
              "      <td>0.339514</td>\n",
              "      <td>0.497814</td>\n",
              "      <td>0.170840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5807</th>\n",
              "      <td>0.392724</td>\n",
              "      <td>False</td>\n",
              "      <td>0.311528</td>\n",
              "      <td>0.424494</td>\n",
              "      <td>0.599304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5808</th>\n",
              "      <td>0.183220</td>\n",
              "      <td>False</td>\n",
              "      <td>0.352198</td>\n",
              "      <td>0.642930</td>\n",
              "      <td>0.678630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5809</th>\n",
              "      <td>0.387226</td>\n",
              "      <td>False</td>\n",
              "      <td>0.106226</td>\n",
              "      <td>-0.038921</td>\n",
              "      <td>0.063332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7734</th>\n",
              "      <td>0.811472</td>\n",
              "      <td>True</td>\n",
              "      <td>1.025497</td>\n",
              "      <td>1.038222</td>\n",
              "      <td>0.905511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7735</th>\n",
              "      <td>0.755061</td>\n",
              "      <td>True</td>\n",
              "      <td>0.714088</td>\n",
              "      <td>0.533547</td>\n",
              "      <td>0.377616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7736</th>\n",
              "      <td>0.375517</td>\n",
              "      <td>False</td>\n",
              "      <td>0.383989</td>\n",
              "      <td>0.519285</td>\n",
              "      <td>0.495733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7737</th>\n",
              "      <td>0.063435</td>\n",
              "      <td>False</td>\n",
              "      <td>0.007947</td>\n",
              "      <td>-0.039301</td>\n",
              "      <td>-0.004630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7738</th>\n",
              "      <td>0.259593</td>\n",
              "      <td>False</td>\n",
              "      <td>0.470496</td>\n",
              "      <td>0.424488</td>\n",
              "      <td>0.463049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1934 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       model_0  target   model_1   model_2   model_3\n",
              "5805  0.261044   False  0.142227  0.157438  0.161204\n",
              "5806  0.533139    True  0.339514  0.497814  0.170840\n",
              "5807  0.392724   False  0.311528  0.424494  0.599304\n",
              "5808  0.183220   False  0.352198  0.642930  0.678630\n",
              "5809  0.387226   False  0.106226 -0.038921  0.063332\n",
              "...        ...     ...       ...       ...       ...\n",
              "7734  0.811472    True  1.025497  1.038222  0.905511\n",
              "7735  0.755061    True  0.714088  0.533547  0.377616\n",
              "7736  0.375517   False  0.383989  0.519285  0.495733\n",
              "7737  0.063435   False  0.007947 -0.039301 -0.004630\n",
              "7738  0.259593   False  0.470496  0.424488  0.463049\n",
              "\n",
              "[1934 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0j-CBAOicNk"
      },
      "source": [
        "def create_random_weight_array(n=4):\n",
        "  percent_weights = np.random.randint(0,100,n) # note this does not randomly distribute them. It is not necessarily even\n",
        "  percent_weights = percent_weights / percent_weights.sum()\n",
        "  return percent_weights"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZNcpGcncWpr"
      },
      "source": [
        "N = 100_000 # 100K takes 15 minutes\n",
        "outcome_lists = np.zeros((N, 5))\n",
        "model_cols = [c for c in prediction_dfs[0].columns if 'model' in c]\n",
        "for i in range(N):\n",
        "  weights = create_random_weight_array()\n",
        "  auprc_scores = np.zeros(5)\n",
        "  for split_num, split_df in enumerate(prediction_dfs):\n",
        "    \n",
        "    weighted_combination = split_df[model_cols].values.dot(weights)\n",
        "    auprc_scores[split_num] = compute_auprc(split_df['target'], weighted_combination)\n",
        "\n",
        "  outcome_lists[i]  =  [*weights, np.mean(auprc_scores)]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1XBAVJ8fF39"
      },
      "source": [
        "weight_ensample_df = pd.DataFrame(outcome_lists)\n",
        "weight_ensample_df.columns = ['weight_1', 'weight_2', 'weight_3', 'weight_4', 'auprc']\n",
        "weight_ensample_df = weight_ensample_df.sort_values('auprc', ascending=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "n6juNX-mqBa8",
        "outputId": "83a08cea-6b43-422e-8df2-f755be6ba104"
      },
      "source": [
        "weight_ensample_df.head(20)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>weight_1</th>\n",
              "      <th>weight_2</th>\n",
              "      <th>weight_3</th>\n",
              "      <th>weight_4</th>\n",
              "      <th>auprc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31079</th>\n",
              "      <td>0.228070</td>\n",
              "      <td>0.508772</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.796028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4834</th>\n",
              "      <td>0.232394</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.183099</td>\n",
              "      <td>0.077465</td>\n",
              "      <td>0.796014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93031</th>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.505155</td>\n",
              "      <td>0.159794</td>\n",
              "      <td>0.097938</td>\n",
              "      <td>0.796001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62021</th>\n",
              "      <td>0.236994</td>\n",
              "      <td>0.502890</td>\n",
              "      <td>0.179191</td>\n",
              "      <td>0.080925</td>\n",
              "      <td>0.795998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11659</th>\n",
              "      <td>0.236842</td>\n",
              "      <td>0.506579</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.098684</td>\n",
              "      <td>0.795997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93146</th>\n",
              "      <td>0.246667</td>\n",
              "      <td>0.493333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.093333</td>\n",
              "      <td>0.795983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85659</th>\n",
              "      <td>0.228814</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.169492</td>\n",
              "      <td>0.101695</td>\n",
              "      <td>0.795982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36697</th>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.510204</td>\n",
              "      <td>0.163265</td>\n",
              "      <td>0.088435</td>\n",
              "      <td>0.795980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97045</th>\n",
              "      <td>0.238636</td>\n",
              "      <td>0.505682</td>\n",
              "      <td>0.176136</td>\n",
              "      <td>0.079545</td>\n",
              "      <td>0.795968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28368</th>\n",
              "      <td>0.231707</td>\n",
              "      <td>0.524390</td>\n",
              "      <td>0.158537</td>\n",
              "      <td>0.085366</td>\n",
              "      <td>0.795968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3257</th>\n",
              "      <td>0.226950</td>\n",
              "      <td>0.524823</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.099291</td>\n",
              "      <td>0.795958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56666</th>\n",
              "      <td>0.211111</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>0.077778</td>\n",
              "      <td>0.795935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60287</th>\n",
              "      <td>0.224719</td>\n",
              "      <td>0.516854</td>\n",
              "      <td>0.146067</td>\n",
              "      <td>0.112360</td>\n",
              "      <td>0.795935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72059</th>\n",
              "      <td>0.237179</td>\n",
              "      <td>0.506410</td>\n",
              "      <td>0.147436</td>\n",
              "      <td>0.108974</td>\n",
              "      <td>0.795934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87793</th>\n",
              "      <td>0.215385</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.107692</td>\n",
              "      <td>0.795917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76204</th>\n",
              "      <td>0.232432</td>\n",
              "      <td>0.481081</td>\n",
              "      <td>0.205405</td>\n",
              "      <td>0.081081</td>\n",
              "      <td>0.795913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57506</th>\n",
              "      <td>0.219653</td>\n",
              "      <td>0.531792</td>\n",
              "      <td>0.173410</td>\n",
              "      <td>0.075145</td>\n",
              "      <td>0.795909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20484</th>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.196970</td>\n",
              "      <td>0.075758</td>\n",
              "      <td>0.795897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39665</th>\n",
              "      <td>0.247253</td>\n",
              "      <td>0.472527</td>\n",
              "      <td>0.186813</td>\n",
              "      <td>0.093407</td>\n",
              "      <td>0.795895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76811</th>\n",
              "      <td>0.243386</td>\n",
              "      <td>0.513228</td>\n",
              "      <td>0.174603</td>\n",
              "      <td>0.068783</td>\n",
              "      <td>0.795895</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       weight_1  weight_2  weight_3  weight_4     auprc\n",
              "31079  0.228070  0.508772  0.157895  0.105263  0.796028\n",
              "4834   0.232394  0.507042  0.183099  0.077465  0.796014\n",
              "93031  0.237113  0.505155  0.159794  0.097938  0.796001\n",
              "62021  0.236994  0.502890  0.179191  0.080925  0.795998\n",
              "11659  0.236842  0.506579  0.157895  0.098684  0.795997\n",
              "93146  0.246667  0.493333  0.166667  0.093333  0.795983\n",
              "85659  0.228814  0.500000  0.169492  0.101695  0.795982\n",
              "36697  0.238095  0.510204  0.163265  0.088435  0.795980\n",
              "97045  0.238636  0.505682  0.176136  0.079545  0.795968\n",
              "28368  0.231707  0.524390  0.158537  0.085366  0.795968\n",
              "3257   0.226950  0.524823  0.148936  0.099291  0.795958\n",
              "56666  0.211111  0.533333  0.177778  0.077778  0.795935\n",
              "60287  0.224719  0.516854  0.146067  0.112360  0.795935\n",
              "72059  0.237179  0.506410  0.147436  0.108974  0.795934\n",
              "87793  0.215385  0.523077  0.153846  0.107692  0.795917\n",
              "76204  0.232432  0.481081  0.205405  0.081081  0.795913\n",
              "57506  0.219653  0.531792  0.173410  0.075145  0.795909\n",
              "20484  0.227273  0.500000  0.196970  0.075758  0.795897\n",
              "39665  0.247253  0.472527  0.186813  0.093407  0.795895\n",
              "76811  0.243386  0.513228  0.174603  0.068783  0.795895"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4crok0ugiD5N",
        "outputId": "05da4ff2-e8e0-4d2a-f7f8-1e4dad01d874"
      },
      "source": [
        "print(weight_ensample_df.head(20).mean())\n",
        "\n",
        "print(weight_ensample_df.head(20).std())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_1    0.232034\n",
            "weight_2    0.508359\n",
            "weight_3    0.169162\n",
            "weight_4    0.090446\n",
            "auprc       0.795955\n",
            "dtype: float64\n",
            "weight_1    0.009602\n",
            "weight_2    0.015332\n",
            "weight_3    0.016236\n",
            "weight_4    0.013102\n",
            "auprc       0.000042\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9qTeOX4rG7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fec70cd-9d35-4b18-d948-f451c10d771e"
      },
      "source": [
        "best_weights =  weight_ensample_df.head(20).mean()\n",
        "print(best_weights)\n",
        "best_weights.to_csv('/content/drive/MyDrive/SpringBoard/Therapeutic Data Commons Projects/HyperParamTuning/best_4_regression_weights.csv')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_1    0.232034\n",
            "weight_2    0.508359\n",
            "weight_3    0.169162\n",
            "weight_4    0.090446\n",
            "auprc       0.795955\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}